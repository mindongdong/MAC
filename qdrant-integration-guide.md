# ê¸°ì¡´ í”„ë¡œì íŠ¸ì— Qdrant RAG í†µí•© ê°€ì´ë“œ

## 1. í˜„ì¬ ìƒíƒœ í™•ì¸ ë° ìˆ˜ì • í•„ìš” íŒŒì¼

ê¸°ì¡´ ë°±ì—”ë“œ êµ¬ì¡°ì—ì„œ ìˆ˜ì •ì´ í•„ìš”í•œ íŒŒì¼ë“¤:
- `app/services/vector_store.py` - Qdrant ì´ˆê¸°í™” ë¡œì§ ë³´ì™„
- `app/services/document_processor.py` - PDF ì²˜ë¦¬ ë¡œì§ ê°œì„ 
- `scripts/ingest_documents.py` - ë¬¸ì„œ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ ê°œì„ 
- `.env` - í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

## 2. ë‹¨ê³„ë³„ í†µí•© ê°€ì´ë“œ

### Step 1: Qdrant ì‹¤í–‰ í™•ì¸

```bash
# 1. Dockerë¡œ Qdrant ì‹¤í–‰
docker run -p 6333:6333 -v $(pwd)/qdrant_data:/qdrant/storage qdrant/qdrant

# 2. Qdrantê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
curl http://localhost:6333/collections
# ë¹ˆ ë°°ì—´ [] ì´ ë‚˜ì˜¤ë©´ ì •ìƒ
```

### Step 2: í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env)

`.env` íŒŒì¼ì— ë‹¤ìŒ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ìˆ˜ì •:

```env
# API Keys
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here  # ì„ë² ë”©ìš©

# Vector Store
VECTOR_STORE_TYPE=qdrant
QDRANT_URL=http://localhost:6333
COLLECTION_NAME=maplestory_docs

# ì„ë² ë”© ì„¤ì •
EMBEDDING_MODEL=text-embedding-ada-002
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
```

### Step 3: Vector Store ì„œë¹„ìŠ¤ ìˆ˜ì •

`app/services/vector_store.py`ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:

```python
# app/services/vector_store.py
from langchain_community.vectorstores import Qdrant
from langchain.schema import Document
from typing import List, Optional
from app.config import settings
import logging
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams

logger = logging.getLogger(__name__)

class VectorStoreService:
    def __init__(self, embeddings):
        self.embeddings = embeddings
        self.client = None
        self.vector_store = self._initialize_vector_store()
    
    def _initialize_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        if settings.vector_store_type == "qdrant":
            # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.client = QdrantClient(
                url=settings.qdrant_url,
                api_key=settings.qdrant_api_key
            )
            
            # ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ìƒì„±
            self._ensure_collection_exists()
            
            # LangChain Qdrant ë˜í¼ ë°˜í™˜
            return Qdrant(
                client=self.client,
                collection_name=settings.collection_name,
                embeddings=self.embeddings
            )
        else:
            raise ValueError(f"Unknown vector store type: {settings.vector_store_type}")
    
    def _ensure_collection_exists(self):
        """ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„±"""
        try:
            # ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸
            collections = self.client.get_collections().collections
            collection_names = [col.name for col in collections]
            
            if settings.collection_name not in collection_names:
                # ì„ë² ë”© ì°¨ì› í™•ì¸
                test_embedding = self.embeddings.embed_query("test")
                vector_size = len(test_embedding)
                
                # ì»¬ë ‰ì…˜ ìƒì„±
                self.client.create_collection(
                    collection_name=settings.collection_name,
                    vectors_config=VectorParams(
                        size=vector_size,
                        distance=Distance.COSINE
                    )
                )
                logger.info(f"Created collection: {settings.collection_name}")
            else:
                logger.info(f"Collection already exists: {settings.collection_name}")
                
        except Exception as e:
            logger.error(f"Error ensuring collection exists: {str(e)}")
            raise
    
    def get_retriever(self, k: int = 5, search_type: str = "similarity"):
        """ë¦¬íŠ¸ë¦¬ë²„ ë°˜í™˜"""
        search_kwargs = {"k": k}
        
        # MMR ê²€ìƒ‰ì¸ ê²½ìš° ì¶”ê°€ íŒŒë¼ë¯¸í„°
        if search_type == "mmr":
            search_kwargs.update({
                "fetch_k": k * 4,  # kì˜ 4ë°° ê°€ì ¸ì™€ì„œ ë‹¤ì–‘ì„± í™•ë³´
                "lambda_mult": 0.5  # ë‹¤ì–‘ì„± vs ê´€ë ¨ì„± ê· í˜•
            })
        
        return self.vector_store.as_retriever(
            search_type=search_type,
            search_kwargs=search_kwargs
        )
    
    async def add_documents(self, documents: List[Document]):
        """ë¬¸ì„œ ì¶”ê°€"""
        try:
            # ë™ê¸° ë©”ì„œë“œ ì‚¬ìš© (LangChain QdrantëŠ” asyncë¥¼ ì™„ì „íˆ ì§€ì›í•˜ì§€ ì•ŠìŒ)
            self.vector_store.add_documents(documents)
            logger.info(f"Added {len(documents)} documents to vector store")
        except Exception as e:
            logger.error(f"Error adding documents: {str(e)}")
            raise
    
    async def search(self, query: str, k: int = 5) -> List[Document]:
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        # ë™ê¸° ë©”ì„œë“œ ì‚¬ìš©
        return self.vector_store.similarity_search(query, k=k)
    
    def get_collection_info(self):
        """ì»¬ë ‰ì…˜ ì •ë³´ ë°˜í™˜"""
        if self.client:
            collection_info = self.client.get_collection(settings.collection_name)
            return {
                "name": collection_info.name,
                "vectors_count": collection_info.vectors_count,
                "points_count": collection_info.points_count,
                "status": collection_info.status
            }
        return None
```

### Step 4: Document Processor ê°œì„ 

`app/services/document_processor.py`ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:

```python
# app/services/document_processor.py
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from typing import List
from langchain.schema import Document
import os
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class DocumentProcessor:
    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separators=["\n\n", "\n", ".", "!", "?", "ã€‚", " ", ""],
            length_function=len
        )
    
    async def process_pdf(self, file_path: str) -> List[Document]:
        """PDF íŒŒì¼ ì²˜ë¦¬ - ê°œì„ ëœ ë²„ì „"""
        try:
            # PDF ë¡œë“œ
            loader = PyPDFLoader(file_path)
            pages = loader.load()
            
            logger.info(f"Loaded PDF: {file_path} ({len(pages)} pages)")
            
            # ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (í˜ì´ì§€ ê²½ê³„ë¥¼ ë¬´ì‹œí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì²­í‚¹ì„ ìœ„í•´)
            full_text = "\n\n".join([page.page_content for page in pages])
            
            # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            filename = os.path.basename(file_path)
            base_metadata = {
                "source": filename,
                "total_pages": len(pages),
                "processed_at": datetime.now().isoformat()
            }
            
            # íŒŒì¼ëª…ì—ì„œ ìë™ íƒœê¹…
            base_metadata.update(self._extract_metadata_from_filename(filename))
            
            # í…ìŠ¤íŠ¸ ë¶„í• 
            chunks = self.text_splitter.split_text(full_text)
            
            # Document ê°ì²´ ìƒì„±
            documents = []
            for i, chunk in enumerate(chunks):
                metadata = base_metadata.copy()
                metadata.update({
                    "chunk_index": i,
                    "total_chunks": len(chunks),
                    "chunk_size": len(chunk)
                })
                
                # ì²« ë²ˆì§¸ ì²­í¬ì—ì„œ ì¶”ê°€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹œë„
                if i == 0:
                    metadata.update(self._extract_metadata_from_content(chunk))
                
                doc = Document(
                    page_content=chunk,
                    metadata=metadata
                )
                documents.append(doc)
            
            logger.info(f"Processed {file_path}: {len(documents)} chunks created")
            return documents
            
        except Exception as e:
            logger.error(f"Error processing PDF {file_path}: {str(e)}")
            raise
    
    def _extract_metadata_from_filename(self, filename: str) -> dict:
        """íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {}
        
        # íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„ (ì˜ˆ: "ë‚˜ì´íŠ¸ë¡œë“œ_5ì°¨ìŠ¤í‚¬_ê°€ì´ë“œ.pdf")
        filename_lower = filename.lower()
        
        # ì§ì—… ê²€ì¶œ
        classes = ["ë‚˜ì´íŠ¸ë¡œë“œ", "ë³´ìš°ë§ˆìŠ¤í„°", "ì•„í¬ë©”ì´ì§€", "ë¹„ìˆ", "íŒ¬í…€", "ì„€ë„ì–´"]
        for class_name in classes:
            if class_name in filename:
                metadata["class"] = class_name
                break
        
        # ì½˜í…ì¸  íƒ€ì… ê²€ì¶œ
        if "5ì°¨" in filename:
            metadata["content_type"] = "5ì°¨ìŠ¤í‚¬"
        elif "ë³´ìŠ¤" in filename:
            metadata["content_type"] = "ë³´ìŠ¤ê³µëµ"
        elif "ì‚¬ëƒ¥í„°" in filename:
            metadata["content_type"] = "ì‚¬ëƒ¥í„°ê°€ì´ë“œ"
        elif "ê°•í™”" in filename:
            metadata["content_type"] = "ê°•í™”ê°€ì´ë“œ"
        
        # ì„œë²„ íƒ€ì… ê²€ì¶œ
        if "ë¦¬ë¶€íŠ¸" in filename:
            metadata["server_type"] = "ë¦¬ë¶€íŠ¸"
        elif "ì¼ë°˜" in filename:
            metadata["server_type"] = "ì¼ë°˜"
        
        return metadata
    
    def _extract_metadata_from_content(self, content: str) -> dict:
        """ì½˜í…ì¸ ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {}
        
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        lines = content.split('\n')
        for line in lines[:20]:  # ì²˜ìŒ 20ì¤„ë§Œ í™•ì¸
            if "ì‘ì„±ì¼:" in line:
                metadata["created_date"] = line.split("ì‘ì„±ì¼:")[-1].strip()
            elif "ê²Œì„ ë²„ì „:" in line:
                metadata["game_version"] = line.split("ê²Œì„ ë²„ì „:")[-1].strip()
            elif "ë‚œì´ë„:" in line:
                metadata["difficulty"] = line.split("ë‚œì´ë„:")[-1].strip()
        
        return metadata
    
    async def process_directory(self, directory: str) -> List[Document]:
        """ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  PDF ì²˜ë¦¬"""
        all_documents = []
        pdf_files = []
        
        # PDF íŒŒì¼ ì°¾ê¸°
        for filename in os.listdir(directory):
            if filename.endswith('.pdf'):
                pdf_files.append(os.path.join(directory, filename))
        
        logger.info(f"Found {len(pdf_files)} PDF files in {directory}")
        
        # ê° PDF ì²˜ë¦¬
        for pdf_path in pdf_files:
            try:
                documents = await self.process_pdf(pdf_path)
                all_documents.extend(documents)
            except Exception as e:
                logger.error(f"Failed to process {pdf_path}: {str(e)}")
                continue
        
        return all_documents
```

### Step 5: ê°œì„ ëœ ë¬¸ì„œ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

`scripts/ingest_documents.py`ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:

```python
# scripts/ingest_documents.py
import asyncio
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.document_processor import DocumentProcessor
from app.services.langchain_service import LangChainService
from app.config import settings
import logging
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn

# Rich console for better output
console = Console()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def check_qdrant_connection():
    """Qdrant ì—°ê²° í™•ì¸"""
    try:
        from qdrant_client import QdrantClient
        client = QdrantClient(url=settings.qdrant_url)
        collections = client.get_collections()
        console.print(f"âœ… Qdrant ì—°ê²° ì„±ê³µ! í˜„ì¬ ì»¬ë ‰ì…˜: {[c.name for c in collections.collections]}", style="green")
        return True
    except Exception as e:
        console.print(f"âŒ Qdrant ì—°ê²° ì‹¤íŒ¨: {str(e)}", style="red")
        return False

async def main():
    """PDF ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ìˆ˜ì§‘"""
    console.print("[bold blue]ë©”ì´í”ŒìŠ¤í† ë¦¬ ë¬¸ì„œ ìˆ˜ì§‘ ì‹œì‘[/bold blue]")
    
    # 1. Qdrant ì—°ê²° í™•ì¸
    if not await check_qdrant_connection():
        console.print("Qdrantë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”: docker run -p 6333:6333 qdrant/qdrant", style="yellow")
        return
    
    # 2. ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task("ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...", total=None)
        
        processor = DocumentProcessor(
            chunk_size=settings.chunk_size,
            chunk_overlap=settings.chunk_overlap
        )
        service = LangChainService()
        
        # ì»¬ë ‰ì…˜ ì •ë³´ ì¶œë ¥
        collection_info = service.vector_store.get_collection_info()
        if collection_info:
            console.print(f"ğŸ“Š í˜„ì¬ ì»¬ë ‰ì…˜ ìƒíƒœ: {collection_info['points_count']} ë¬¸ì„œ", style="cyan")
    
    # 3. PDF ë””ë ‰í† ë¦¬ í™•ì¸
    pdf_dir = "./data/pdfs"
    if not os.path.exists(pdf_dir):
        os.makedirs(pdf_dir)
        console.print(f"ğŸ“ PDF ë””ë ‰í† ë¦¬ ìƒì„±: {pdf_dir}", style="yellow")
        console.print("PDF íŒŒì¼ì„ ì´ ë””ë ‰í† ë¦¬ì— ë„£ì–´ì£¼ì„¸ìš”.", style="yellow")
        return
    
    # 4. PDF ì²˜ë¦¬
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task("PDF ì²˜ë¦¬ ì¤‘...", total=None)
        
        documents = await processor.process_directory(pdf_dir)
        
        if not documents:
            console.print("âŒ ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.", style="red")
            return
        
        console.print(f"ğŸ“„ ì´ {len(documents)} ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ", style="green")
    
    # 5. ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task("ë²¡í„° ìŠ¤í† ì–´ì— ì—…ë¡œë“œ ì¤‘...", total=None)
        
        await service.add_documents(documents)
        
        console.print("âœ… ë¬¸ì„œ ì—…ë¡œë“œ ì™„ë£Œ!", style="green")
    
    # 6. ìµœì¢… ìƒíƒœ í™•ì¸
    final_info = service.vector_store.get_collection_info()
    if final_info:
        console.print(f"ğŸ“Š ìµœì¢… ì»¬ë ‰ì…˜ ìƒíƒœ: {final_info['points_count']} ë¬¸ì„œ", style="cyan")
    
    console.print("\n[bold green]ë¬¸ì„œ ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤![/bold green]")
    console.print("ì´ì œ ì„œë²„ë¥¼ ì‹¤í–‰í•˜ê³  ì§ˆë¬¸í•´ë³´ì„¸ìš”: uvicorn app.main:app --reload")

if __name__ == "__main__":
    asyncio.run(main())
```

### Step 6: í…ŒìŠ¤íŠ¸ìš© PDF ì¤€ë¹„

`data/pdfs/` ë””ë ‰í† ë¦¬ì— í…ŒìŠ¤íŠ¸ìš© PDFë¥¼ ë„£ì–´ì£¼ì„¸ìš”. ì˜ˆì‹œ êµ¬ì¡°:

```
data/
â””â”€â”€ pdfs/
    â””â”€â”€ ë‚˜ì´íŠ¸ë¡œë“œ_5ì°¨ìŠ¤í‚¬_ê°€ì´ë“œ.pdf
```

### Step 7: ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

`scripts/test_rag.py` íŒŒì¼ì„ ë§Œë“¤ì–´ í…ŒìŠ¤íŠ¸:

```python
# scripts/test_rag.py
import asyncio
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.langchain_service import LangChainService
from rich.console import Console
from rich.markdown import Markdown

console = Console()

async def test_questions():
    """RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = LangChainService()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "ë‚˜ì´íŠ¸ë¡œë“œ 5ì°¨ ìŠ¤í‚¬ ì¤‘ì— ë­ê°€ ì œì¼ ì¤‘ìš”í•´?",
        "ë³´ìŠ¤ì „ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìŠ¤í‚¬ ìˆœì„œ ì•Œë ¤ì¤˜",
        "ì´ˆë³´ìê°€ ë‚˜ì´íŠ¸ë¡œë“œ ì‹œì‘í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼í•´?"
    ]
    
    for question in test_questions:
        console.print(f"\n[bold yellow]â“ ì§ˆë¬¸:[/bold yellow] {question}")
        
        try:
            # ì§ˆë¬¸ ì‹¤í–‰
            result = await service.chat(
                message=question,
                session_id="test-session",
                stream=False
            )
            
            # ë‹µë³€ ì¶œë ¥
            console.print("\n[bold green]ğŸ’¬ ë‹µë³€:[/bold green]")
            console.print(Markdown(result["response"]))
            
            # ì¶œì²˜ ì¶œë ¥
            if result.get("sources"):
                console.print("\n[bold blue]ğŸ“š ì°¸ê³  ë¬¸ì„œ:[/bold blue]")
                for source in result["sources"]:
                    console.print(f"- {source['title']} (p.{source['page']})")
            
        except Exception as e:
            console.print(f"[red]ì˜¤ë¥˜ ë°œìƒ: {str(e)}[/red]")
        
        console.print("-" * 50)

if __name__ == "__main__":
    asyncio.run(test_questions())
```

## 3. ì‹¤í–‰ ìˆœì„œ

```bash
# 1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (requirements.txtì— ì¶”ê°€)
pip install qdrant-client rich

# 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ í¸ì§‘í•˜ì—¬ API í‚¤ ì…ë ¥

# 3. Qdrant ì‹¤í–‰
docker run -p 6333:6333 -v $(pwd)/qdrant_data:/qdrant/storage qdrant/qdrant

# 4. PDF íŒŒì¼ ì¤€ë¹„
# data/pdfs/ ë””ë ‰í† ë¦¬ì— PDF íŒŒì¼ ë³µì‚¬

# 5. ë¬¸ì„œ ìˆ˜ì§‘
python scripts/ingest_documents.py

# 6. í…ŒìŠ¤íŠ¸
python scripts/test_rag.py

# 7. ì„œë²„ ì‹¤í–‰
uvicorn app.main:app --reload
```

## 4. ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **Qdrant ì—°ê²° ì˜¤ë¥˜**
   ```bash
   # Qdrantê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
   curl http://localhost:6333/collections
   ```

2. **ì„ë² ë”© ì˜¤ë¥˜**
   ```python
   # OpenAI API í‚¤ í™•ì¸
   echo $OPENAI_API_KEY
   ```

3. **PDF ì²˜ë¦¬ ì˜¤ë¥˜**
   ```bash
   # pypdf ì¬ì„¤ì¹˜
   pip install --upgrade pypdf
   ```

### ë””ë²„ê¹… íŒ

1. **ë¡œê·¸ ë ˆë²¨ ë³€ê²½**
   ```python
   # app/config.pyì— ì¶”ê°€
   LOG_LEVEL = "DEBUG"
   ```

2. **ì»¬ë ‰ì…˜ ìƒíƒœ í™•ì¸**
   ```python
   # Python ì½˜ì†”ì—ì„œ
   from qdrant_client import QdrantClient
   client = QdrantClient(url="http://localhost:6333")
   print(client.get_collection("maplestory_docs"))
   ```

## 5. ë‹¤ìŒ ë‹¨ê³„

PDF í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí•˜ë©´:

1. **Markdownìœ¼ë¡œ ì „í™˜**: PDF ëŒ€ì‹  Markdown ì‚¬ìš©
2. **ì„±ëŠ¥ ìµœì í™”**: ìºì‹±, ë°°ì¹˜ ì²˜ë¦¬ ì¶”ê°€
3. **UI ê°œì„ **: ì›¹ ì¸í„°í˜ì´ìŠ¤ ì¶”ê°€
4. **ë””ìŠ¤ì½”ë“œ ë´‡**: ë””ìŠ¤ì½”ë“œ í†µí•©

ì´ì œ ìœ„ ê°€ì´ë“œë¥¼ ë”°ë¼ ì§„í–‰í•´ë³´ì‹œê³ , ë§‰íˆëŠ” ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì•Œë ¤ì£¼ì„¸ìš”!