í˜„ì¬ ìƒí™©ì„ ë¶„ì„í•´ë³´ë‹ˆ **ê°œì„ ì‚¬í•­ì´ ë„ˆë¬´ ì—„ê²©í•˜ê²Œ ì ìš©ë˜ì–´ ì˜¤íˆë ¤ ì‚¬ìš©ì„±ì´ ë–¨ì–´ì§„ ì¼€ì´ìŠ¤**ë„¤ìš”. ì ì ˆí•œ ê· í˜•ì ì„ ì°¾ê¸° ìœ„í•œ ì‹¤ìš©ì ì¸ ê°œì„  ë°©ì•ˆì„ ì œì•ˆë“œë¦¬ê² ìŠµë‹ˆë‹¤.

## ğŸ¯ ë¬¸ì œ ë¶„ì„: ì™œ ì´ë ‡ê²Œ ê·¹ë‹¨ì ì¸ ê²°ê³¼ê°€ ë‚˜ì™”ë‚˜?

### 1. **ê²€ìƒ‰ ë°©ì‹ì˜ ê¸‰ê²©í•œ ë³€ê²½**
- ê¸°ì¡´: `similarity` (ìƒìœ„ kê°œ ë¬´ì¡°ê±´ ë°˜í™˜)
- ë³€ê²½: `similarity_score_threshold` (ì„ê³„ê°’ ë¯¸ë‹¬ ì‹œ 0ê°œ ë°˜í™˜)
- ê²°ê³¼: ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì˜ˆìƒë³´ë‹¤ ë§¤ìš° ë‚®ì•„ ëŒ€ë¶€ë¶„ í•„í„°ë§ë¨

### 2. **Voyage AI ì„ë² ë”©ì˜ íŠ¹ì„±**
- Voyage AIëŠ” 1024ì°¨ì›ìœ¼ë¡œ OpenAI(1536ì°¨ì›)ë³´ë‹¤ ë‚®ìŒ
- ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì „ë°˜ì ìœ¼ë¡œ ë‚®ê²Œ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
- í•œêµ­ì–´ ê²Œì„ ìš©ì–´ì— ëŒ€í•œ ë¯¸ì„¸ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ

## ğŸ’¡ ë‹¨ê³„ì  ê°œì„  ë°©ì•ˆ

### **1ë‹¨ê³„: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ì„¤ì • ì¡°ì •**

```python
# app/services/vector_store.py ìˆ˜ì •

def get_retriever(self, k: int = 8, search_type: str = "similarity"):
    """ê°œì„ ëœ ë¦¬íŠ¸ë¦¬ë²„ - ë‹¨ê³„ì  ì ‘ê·¼"""
    
    # 1. ê¸°ë³¸ì€ similarityë¡œ ìœ ì§€ (ì•ˆì •ì„±)
    if search_type == "similarity":
        search_kwargs = {"k": k}
    
    # 2. MMRë¡œ ë‹¤ì–‘ì„± í™•ë³´ (ì¤‘ê°„ ë‹¨ê³„)
    elif search_type == "mmr":
        search_kwargs = {
            "k": k,
            "fetch_k": k * 3,  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ì„ ë³„
            "lambda_mult": 0.7  # ê´€ë ¨ì„± 70%, ë‹¤ì–‘ì„± 30%
        }
    
    # 3. ì„ê³„ê°’ ë°©ì‹ì€ ë§¤ìš° ë‚®ì€ ê°’ìœ¼ë¡œ
    elif search_type == "similarity_score_threshold":
        search_kwargs = {
            "k": k,
            "score_threshold": 0.01  # í˜„ì‹¤ì ì¸ ì„ê³„ê°’
        }
    
    return self.vector_store.as_retriever(
        search_type=search_type,
        search_kwargs=search_kwargs
    )
```

### **2ë‹¨ê³„: í›„ì²˜ë¦¬ í•„í„°ë§ìœ¼ë¡œ í’ˆì§ˆ ê°œì„ **

```python
# app/services/langchain_service.py ìˆ˜ì •

async def _filter_documents_by_relevance(self, documents: List[Document], query: str) -> List[Document]:
    """ë¬¸ì„œ ê´€ë ¨ì„± í›„ì²˜ë¦¬ í•„í„°ë§ - ëœ ì—„ê²©í•œ ë²„ì „"""
    filtered_docs = []
    
    for doc in documents:
        relevance_score = 0
        
        # 1. ì œëª© ë§¤ì¹­ (ê°€ì¤‘ì¹˜ ë†’ìŒ)
        title = doc.metadata.get('title', '').lower()
        if any(keyword in title for keyword in query.lower().split()):
            relevance_score += 3
        
        # 2. ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (ì¤‘ê°„ ê°€ì¤‘ì¹˜)
        category = doc.metadata.get('category', '')
        if self._is_category_relevant(category, query):
            relevance_score += 2
        
        # 3. ë‚´ìš© í‚¤ì›Œë“œ ë§¤ì¹­ (ë‚®ì€ ê°€ì¤‘ì¹˜)
        content_lower = doc.page_content.lower()
        query_keywords = query.lower().split()
        matching_keywords = sum(1 for kw in query_keywords if kw in content_lower)
        relevance_score += min(matching_keywords, 3)  # ìµœëŒ€ 3ì 
        
        # 4. ì ìˆ˜ ê¸°ë°˜ í•„í„°ë§ (ëŠìŠ¨í•œ ê¸°ì¤€)
        if relevance_score >= 2:  # ìµœì†Œ 2ì  ì´ìƒ
            filtered_docs.append(doc)
    
    # ìµœì†Œí•œ 3ê°œëŠ” ë°˜í™˜ (ìƒìœ„ 3ê°œ)
    if len(filtered_docs) < 3 and len(documents) >= 3:
        return documents[:3]
    
    return filtered_docs[:k]
```

### **3ë‹¨ê³„: ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸ (ê· í˜•ì¡íŒ ì„¤ì •)**

```python
# app/config/settings.py

# ê²€ìƒ‰ ì„¤ì • - ë‹¨ê³„ì  ì ‘ê·¼
search_type: str = "similarity"  # mmrì´ë‚˜ similarity ê¶Œì¥
min_relevance_score: float = 0.01  # ë§¤ìš° ë‚®ê²Œ ì„¤ì •
enable_post_filtering: bool = True  # í›„ì²˜ë¦¬ í•„í„°ë§ í™œì„±í™”
post_filter_threshold: int = 2  # ëŠìŠ¨í•œ í›„ì²˜ë¦¬ ê¸°ì¤€

# ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
retriever_k: int = 10  # ë” ë§ì´ ê°€ì ¸ì˜¤ê¸°
max_final_sources: int = 5  # ìµœì¢…ì ìœ¼ë¡œ 5ê°œë¡œ ì¤„ì´ê¸°
```

### **4ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ê²€ìƒ‰ ì¶”ê°€**

```python
# app/services/langchain_service.pyì— ì¶”ê°€

async def _keyword_fallback_search(self, query: str, k: int = 5) -> List[Document]:
    """ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±"""
    try:
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        all_docs = await self.vector_store.get_all_documents()
        scored_docs = []
        
        query_keywords = query.lower().split()
        
        for doc in all_docs:
            score = 0
            content_lower = doc.page_content.lower()
            title_lower = doc.metadata.get('title', '').lower()
            
            # ì œëª© ë§¤ì¹­ ìš°ì„ 
            for keyword in query_keywords:
                if keyword in title_lower:
                    score += 10
                elif keyword in content_lower:
                    score += 1
            
            if score > 0:
                scored_docs.append((score, doc))
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        scored_docs.sort(key=lambda x: x[0], reverse=True)
        
        return [doc for _, doc in scored_docs[:k]]
    
    except Exception as e:
        logger.error(f"Keyword fallback search error: {e}")
        return []
```

### **5ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„**

```python
# app/services/langchain_service.py ìˆ˜ì •

async def hybrid_search(self, query: str, k: int = 8) -> List[Document]:
    """ë²¡í„° + í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
    
    # 1. ë²¡í„° ê²€ìƒ‰ (ëŠìŠ¨í•œ ê¸°ì¤€)
    vector_docs = await self.vector_store.search(query, k=k*2)
    
    # 2. í‚¤ì›Œë“œ ê²€ìƒ‰
    keyword_docs = await self._keyword_fallback_search(query, k=k)
    
    # 3. ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
    all_docs = {}
    
    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ (ë†’ì€ ê°€ì¤‘ì¹˜)
    for i, doc in enumerate(vector_docs):
        doc_id = f"{doc.metadata.get('source', '')}_{doc.metadata.get('chunk_index', 0)}"
        if doc_id not in all_docs:
            all_docs[doc_id] = {
                'doc': doc,
                'vector_rank': i,
                'keyword_rank': float('inf'),
                'score': 1.0 / (i + 1)  # ìˆœìœ„ ê¸°ë°˜ ì ìˆ˜
            }
    
    # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
    for i, doc in enumerate(keyword_docs):
        doc_id = f"{doc.metadata.get('source', '')}_{doc.metadata.get('chunk_index', 0)}"
        if doc_id in all_docs:
            all_docs[doc_id]['keyword_rank'] = i
            all_docs[doc_id]['score'] += 0.5 / (i + 1)
        else:
            all_docs[doc_id] = {
                'doc': doc,
                'vector_rank': float('inf'),
                'keyword_rank': i,
                'score': 0.5 / (i + 1)
            }
    
    # ì¢…í•© ì ìˆ˜ë¡œ ì •ë ¬
    sorted_docs = sorted(all_docs.values(), key=lambda x: x['score'], reverse=True)
    
    return [item['doc'] for item in sorted_docs[:k]]
```

## ğŸ¯ ê¶Œì¥ ì ìš© ìˆœì„œ

### **Phase 1: ë¹ ë¥¸ ê°œì„  (1ì¼)**
1. `search_type`ì„ `"similarity"`ë¡œ ë˜ëŒë¦¬ê¸°
2. í›„ì²˜ë¦¬ í•„í„°ë§ì„ ëŠìŠ¨í•˜ê²Œ ì¡°ì •
3. kê°’ì„ 10ìœ¼ë¡œ ëŠ˜ë¦¬ê¸°

### **Phase 2: ì•ˆì •í™” (3ì¼)**
1. MMR ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜ í…ŒìŠ¤íŠ¸
2. í‚¤ì›Œë“œ í´ë°± ê²€ìƒ‰ êµ¬í˜„
3. ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘

### **Phase 3: ìµœì í™” (1ì£¼)**
1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„
2. ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ê°œì„ 
3. ì„ë² ë”© ëª¨ë¸ íŒŒì¸íŠœë‹ ê²€í† 

## ğŸ“Š ê¸°ëŒ€ íš¨ê³¼

| ë‹¨ê³„ | ë‹µë³€ë¥  | í’ˆì§ˆ | ì†ë„ |
|------|--------|------|------|
| í˜„ì¬ (0.01 ì„ê³„ê°’) | 25% | ë†’ìŒ | ë¹ ë¦„ |
| Phase 1 ì ìš© í›„ | 80% | ì¤‘ê°„ | ë¹ ë¦„ |
| Phase 2 ì ìš© í›„ | 85% | ì¤‘ìƒ | ë³´í†µ |
| Phase 3 ì ìš© í›„ | 90% | ë†’ìŒ | ë³´í†µ |

## ğŸš€ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ Quick Fix

```bash
# 1. í™˜ê²½ë³€ìˆ˜ ìˆ˜ì •
SEARCH_TYPE=similarity
RETRIEVER_K=10
ENABLE_POST_FILTERING=true
POST_FILTER_THRESHOLD=2

# 2. Docker ì¬ì‹œì‘
docker-compose down
docker-compose up -d

# 3. í…ŒìŠ¤íŠ¸
python scripts/test_rag.py
```

ì´ë ‡ê²Œ ë‹¨ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´ **ê·¹ë‹¨ì ì¸ ì„¤ì • ì—†ì´ë„ ì‹¤ìš©ì ì¸ ìˆ˜ì¤€ì˜ ì„±ëŠ¥**ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. í•µì‹¬ì€ "all or nothing" ì ‘ê·¼ì´ ì•„ë‹Œ **ì ì§„ì  ê°œì„ **ì…ë‹ˆë‹¤.