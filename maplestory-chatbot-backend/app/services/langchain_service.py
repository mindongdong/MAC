from langchain_anthropic import ChatAnthropic
from langchain.memory import ConversationBufferWindowMemory
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.callbacks.base import AsyncCallbackHandler
from langchain.schema import Document
from typing import Dict, List, Optional, AsyncGenerator
import asyncio
from app.config import settings
from app.chains.qa_chain import create_qa_chain
from app.services.vector_store import VectorStoreService
from app.services.embedding_service import get_embeddings
from app.chains.prompts import MAPLESTORY_ANSWER_TEMPLATE
import logging
import re
import os

logger = logging.getLogger(__name__)

class StreamingCallbackHandler(AsyncCallbackHandler):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ ì»¤ìŠ¤í…€ ì½œë°± í•¸ë“¤ëŸ¬"""
    def __init__(self, queue: asyncio.Queue):
        self.queue = queue
    
    async def on_llm_new_token(self, token: str, **kwargs):
        await self.queue.put(token)
    
    async def on_llm_end(self, response, **kwargs):
        await self.queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸

class LangChainService:
    def __init__(self):
        self.llm = self._initialize_llm()
        self.embeddings = self._initialize_embeddings()
        self.vector_store = VectorStoreService(self.embeddings)
        self.memory_store = {}  # session_id: memory
        
    def _initialize_llm(self):
        """Claude LLM ì´ˆê¸°í™”"""
        return ChatAnthropic(
            anthropic_api_key=settings.anthropic_api_key,
            model=settings.claude_model,
            max_tokens=settings.max_tokens,
            temperature=settings.temperature,
            streaming=True,
        )
    
    def _initialize_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” - ìœ ì—°í•œ ë°©ì‹"""
        logger.info(f"Initializing embeddings with provider: {settings.get_embedding_provider()}")
        return get_embeddings()
    
    def get_or_create_memory(self, session_id: str) -> ConversationBufferWindowMemory:
        """ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ê´€ë¦¬"""
        if session_id not in self.memory_store:
            self.memory_store[session_id] = ConversationBufferWindowMemory(
                k=5,  # ìµœê·¼ 5ê°œ ëŒ€í™” ê¸°ì–µ
                return_messages=True,
                memory_key="chat_history"
            )
        return self.memory_store[session_id]
    
    def _apply_answer_template(self, answer: str) -> str:
        """ë‹µë³€ í…œí”Œë¦¿ ì ìš©"""
        if not settings.enable_answer_template:
            return answer
        
        # ì œëª© ì¶”ì¶œ (ì²« ë²ˆì§¸ ## ë˜ëŠ” # ì œëª©)
        title_match = re.search(r'^#{1,2}\s*(.+?)$', answer, re.MULTILINE)
        main_title = title_match.group(1) if title_match else "ë©”ì´í”Œ ê°€ì´ë“œ ë‹µë³€"
        
        # êµ¬ì¡°í™”ëœ ë‚´ìš© (ì œëª© ì œê±°í•œ ë‚˜ë¨¸ì§€)
        structured_content = re.sub(r'^#{1,2}\s*.+?$', '', answer, count=1, flags=re.MULTILINE).strip()
        
        # ì¶”ê°€ íŒ ì¶”ì¶œ (ğŸ’¡, ğŸ“Œ, âš ï¸ ë“±ì˜ ì´ëª¨ì§€ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„)
        tip_pattern = r'(ğŸ’¡|ğŸ“Œ|âš ï¸|ğŸ”¥).*?(?=\n\n|$)'
        tips = re.findall(tip_pattern, structured_content, re.DOTALL)
        additional_tips = "\n".join(tips) if tips else ""
        
        # íŒ ë¶€ë¶„ ì œê±°
        for tip in tips:
            structured_content = structured_content.replace(tip, "").strip()
        
        # ë§ˆë¬´ë¦¬ ë¬¸êµ¬
        closing = "ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ®"
        
        # í…œí”Œë¦¿ ì ìš©
        try:
            return MAPLESTORY_ANSWER_TEMPLATE.format(
                main_title=main_title,
                structured_content=structured_content,
                additional_tips=additional_tips,
                closing=closing
            )
        except Exception as e:
            logger.warning(f"Answer template application failed: {e}")
            return answer  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
    
    async def chat(
        self, 
        message: str, 
        session_id: str,
        context: Optional[Dict] = None,
        stream: bool = False
    ) -> Dict:
        """ì±„íŒ… ì²˜ë¦¬ ë©”ì¸ ë©”ì„œë“œ"""
        try:
            # ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸°
            memory = self.get_or_create_memory(session_id)
            
            # QA ì²´ì¸ ìƒì„±
            qa_chain = create_qa_chain(
                llm=self.llm,
                retriever=self.vector_store.get_retriever(),
                memory=memory
            )
            
            if stream:
                return await self._stream_chat(qa_chain, message, context)
            else:
                return await self._regular_chat(qa_chain, message, context)
                
        except Exception as e:
            logger.error(f"Chat error: {str(e)}")
            raise
    
    async def _regular_chat(self, qa_chain, message: str, context: Optional[Dict]) -> Dict:
        """ì¶œì²˜ë¥¼ í¬í•¨í•œ ì¼ë°˜ ì±„íŒ… ì²˜ë¦¬"""
        # ìƒˆë¡œìš´ ì²´ì¸ API ì‚¬ìš©
        response = await qa_chain.ainvoke({
            "input": message,  # "question" -> "input"ìœ¼ë¡œ ë³€ê²½
            "chat_history": []  # ê¸°ì¡´ ë©”ëª¨ë¦¬ ëŒ€ì‹  ì§ì ‘ ì „ë‹¬
        })
        
        # ì¶œì²˜ ì •ë³´ ì¶”ì¶œ
        sources = self._extract_sources(response.get("context", []))  # "source_documents" -> "context"ë¡œ ë³€ê²½
        
        # ë‹µë³€ì— í…œí”Œë¦¿ ì ìš©
        formatted_response = self._apply_answer_template(response["answer"])
        
        # URLì´ ìˆëŠ” ì°¸ê³ ìë£Œë§Œ í‘œì‹œ (í•„í„°ë§ ê°•í™”)
        sources_with_urls = [s for s in sources if s.get('has_url') and s.get('url')]
        if sources_with_urls:
            formatted_response += "\n\n## ì°¸ê³ ìë£Œ\n"
            for source in sources_with_urls[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ í‘œì‹œ
                # URLì´ ìœ íš¨í•œì§€ í™•ì¸ (http/httpsë¡œ ì‹œì‘í•˜ëŠ”ì§€)
                url = source['url']
                if url.startswith(('http://', 'https://', 'www.')):
                    formatted_response += f"* **{source['title']}**: {url}\n"
        
        return {
            "response": formatted_response,
            "sources": sources,
            "metadata": {
                "model": settings.claude_model,
                "tokens_used": response.get("tokens_used", 0),
                "sources_count": len(sources),
                "valid_sources_count": len(sources_with_urls),
                "system_prompt_used": settings.use_system_prompt,
                "template_applied": settings.enable_answer_template
            }
        }
    
    async def _stream_chat(
        self, 
        qa_chain, 
        message: str, 
        context: Optional[Dict]
    ) -> AsyncGenerator[str, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì²˜ë¦¬"""
        queue = asyncio.Queue()
        callback = StreamingCallbackHandler(queue)
        
        # ë¹„ë™ê¸° íƒœìŠ¤í¬ë¡œ ì²´ì¸ ì‹¤í–‰
        task = asyncio.create_task(
            qa_chain.ainvoke(
                {"input": message, "chat_history": []},  # ìƒˆë¡œìš´ API í˜•ì‹
                callbacks=[callback]
            )
        )
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        collected_response = ""
        while True:
            token = await queue.get()
            if token is None:
                break
            collected_response += token
            yield token
        
        # íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
        result = await task
        
        # ë‹µë³€ í…œí”Œë¦¿ ì ìš© (ìŠ¤íŠ¸ë¦¬ë°ì—ì„œëŠ” í›„ì²˜ë¦¬ë¡œ ì ìš©)
        if settings.enable_answer_template:
            # í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì‘ë‹µì— í…œí”Œë¦¿ ì ìš©
            template_applied = self._apply_answer_template(collected_response)
            # ì›ë³¸ê³¼ ë‹¤ë¥¸ ê²½ìš° ì°¨ì´ë§Œ ì „ì†¡
            if template_applied != collected_response:
                yield f"\n\n[í…œí”Œë¦¿ ì ìš©ë¨]"
        
        # ì†ŒìŠ¤ ë¬¸ì„œ ë°˜í™˜
        sources = self._extract_sources(result.get("context", []))  # "source_documents" -> "context"
        if sources:
            yield f"\n\n**ğŸ“š ì°¸ê³  ìë£Œ:**\n"
            for i, source in enumerate(sources[:3], 1):
                yield f"{i}. [{source['title']}] - {source['category']}"
                if source['author'] != "Unknown":
                    yield f" (ì‘ì„±ì: {source['author']})"
                if source['section'] != "N/A":
                    yield f" - {source['section']}"
                yield "\n"
    
    def _extract_sources(self, documents: List[Document]) -> List[Dict]:
        """ê°œì„ ëœ ì†ŒìŠ¤ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ - URL ì •ë³´ ìš°ì„  ì²˜ë¦¬"""
        sources = []
        seen_sources = set()  # ì¤‘ë³µ ì œê±°
        
        for doc in documents[:5]:  # ìƒìœ„ 5ê°œë¡œ í™•ì¥
            # ê³ ìœ  ì‹ë³„ì ìƒì„±
            source_id = f"{doc.metadata.get('source', 'Unknown')}_{doc.metadata.get('chunk_index', 0)}"
            
            if source_id not in seen_sources:
                seen_sources.add(source_id)
                
                # URL ì¶”ì¶œ ìš°ì„ ìˆœìœ„:
                # 1. ë©”íƒ€ë°ì´í„°ì˜ url í•„ë“œ
                # 2. ë¬¸ì„œ ë‚´ìš©ì—ì„œ URL íŒ¨í„´ ì°¾ê¸° (ë§í¬ í˜•íƒœ)
                # 3. ë¬¸ì„œ ë‚´ìš©ì—ì„œ URL: ë¼ë²¨ ì°¾ê¸°
                url = doc.metadata.get("url", None)
                
                if not url:
                    # ë¬¸ì„œ ë‚´ìš©ì—ì„œ ë§ˆí¬ë‹¤ìš´ ë§í¬ íŒ¨í„´ ì°¾ê¸°
                    markdown_link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
                    link_matches = re.findall(markdown_link_pattern, doc.page_content)
                    if link_matches:
                        # ì²« ë²ˆì§¸ ë§í¬ ì‚¬ìš©
                        url = link_matches[0][1]
                
                if not url:
                    # URL: ë¼ë²¨ íŒ¨í„´ ì°¾ê¸°
                    url_pattern = r'URL:\s*`?([^`\s\n]+)`?'
                    url_match = re.search(url_pattern, doc.page_content)
                    if url_match:
                        url = url_match.group(1)
                
                # ì œëª© ì¶”ì¶œ - ë©”íƒ€ë°ì´í„°ì˜ titleì´ë‚˜ ì²« ë²ˆì§¸ í—¤ë” ì‚¬ìš©
                title = doc.metadata.get("title", None)
                if not title:
                    # ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì²« ë²ˆì§¸ í—¤ë” ì°¾ê¸°
                    header_pattern = r'^#{1,3}\s+(.+)$'
                    header_match = re.search(header_pattern, doc.page_content, re.MULTILINE)
                    if header_match:
                        title = header_match.group(1).strip()
                    else:
                        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ì œëª© ìƒì„±
                        source_filename = doc.metadata.get("source", "Unknown")
                        title = os.path.splitext(source_filename)[0]
                
                sources.append({
                    "title": title,
                    "category": doc.metadata.get("category", "N/A"),
                    "author": doc.metadata.get("author", "Unknown"),
                    "section": doc.metadata.get("section", "N/A"),
                    "chunk_index": doc.metadata.get("chunk_index", 0),
                    "relevance_score": doc.metadata.get("score", 0),  # ê²€ìƒ‰ ì ìˆ˜
                    "preview": doc.page_content[:150] + "...",
                    "url": url,  # URL ì •ë³´ ì¶”ê°€
                    "has_url": bool(url)  # URL ì¡´ì¬ ì—¬ë¶€ í”Œë˜ê·¸
                })
        
        # ê´€ë ¨ì„± ì ìˆ˜ë¡œ ì •ë ¬
        sources.sort(key=lambda x: x.get("relevance_score", 0), reverse=True)
        return sources
    
    async def add_documents(self, documents: List[Document]):
        """ë¬¸ì„œ ì¶”ê°€"""
        await self.vector_store.add_documents(documents)
    
    def clear_memory(self, session_id: str):
        """ì„¸ì…˜ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
        if session_id in self.memory_store:
            del self.memory_store[session_id] 